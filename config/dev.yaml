env: dev
environment: emr  # Set to 'emr' for EMR Serverless execution

project_name: project-a

aws:
  region: us-east-1
  account_id: "424570854632"
  kms_key_arn: "arn:aws:kms:us-east-1:424570854632:key/66576e98-a4e4-4b87-8b61-4357c39d0886"

buckets:
  lake: "my-etl-lake-demo-424570854632"
  artifacts: "my-etl-artifacts-demo-424570854632"
  logs: "my-etl-logs-demo-424570854632"
  code: "my-etl-code-demo-424570854632"

glue:
  bronze_db: "project-a_bronze_dev"   # actual TF name
  silver_db: "project-a_silver_dev"
  gold_db: "project-a_gold_dev"

emr:
  application_id: "00g0tm6kccmdcf09"
  execution_role_arn: "arn:aws:iam::424570854632:role/project-a-dev-emr-exec"
  driver:
    cores: 2
    memory: "4G"
  executor:
    cores: 2
    memory: "8G"

paths:
  bronze_root: "s3://my-etl-lake-demo-424570854632/bronze"
  silver_root: "s3://my-etl-lake-demo-424570854632/silver"
  gold_root:   "s3://my-etl-lake-demo-424570854632/gold"
  checkpoints_root: "s3://my-etl-lake-demo-424570854632/_checkpoints"
  dq_results_root:  "s3://my-etl-lake-demo-424570854632/_dq_results"

# Source file definitions - single source of truth
sources:
  crm:
    base_path: "s3://my-etl-lake-demo-424570854632/bronze/crm"
    files:
      accounts: "accounts.csv"
      contacts: "contacts.csv"
      opportunities: "opportunities.csv"
  
  redshift:
    base_path: "s3://my-etl-lake-demo-424570854632/bronze/redshift"
    files:
      behavior: "redshift_customer_behavior_50000.csv"
    incremental_dirs:
      behavior: "s3://my-etl-lake-demo-424570854632/bronze/redshift/behavior/daily"
  
  snowflake:
    base_path: "s3://my-etl-lake-demo-424570854632/bronze/snowflake"
    files:
      customers: "snowflake_customers_50000.csv"
      orders: "snowflake_orders_100000.csv"
      products: "snowflake_products_10000.csv"
    incremental_dirs:
      orders: "s3://my-etl-lake-demo-424570854632/bronze/snowflake/orders/daily"
  
  fx:
    type: json
    base_path: "s3://my-etl-lake-demo-424570854632/bronze/fx"
    raw_path: "s3://my-etl-lake-demo-424570854632/bronze/fx/json/"
    bronze_path: "s3://my-etl-lake-demo-424570854632/bronze/fx/delta/"
    silver_path: "s3://my-etl-lake-demo-424570854632/silver/fx/"
    files:
      daily_rates: "fx_rates_historical_730_days.csv"
      daily_rates_json: "fx_rates_historical.json"  # JSON Lines format
    base_currency: "USD"
    expected_currencies: ["USD", "EUR", "GBP", "JPY", "INR", "CHF", "CAD", "AUD", "CNY"]
  
  kafka_sim:
    base_path: "s3://my-etl-lake-demo-424570854632/bronze/kafka"
    files:
      orders_seed: "stream_kafka_events_100000.csv"
    incremental_dirs:
      events: "s3://my-etl-lake-demo-424570854632/bronze/kafka/events/daily"

  kafka:
    local_bootstrap_servers: "localhost:9092"
    topic: "orders_events"
    schema_registry_path: "config/schema_registry/kafka/orders_events.json"
    dlq_path: "s3://my-etl-lake-demo-424570854632/bronze/kafka/dlq/orders_events"

# Table name definitions for Silver and Gold layers
tables:
  silver:
    customers: "customers_silver"
    orders: "orders_silver"
    products: "products_silver"
    behavior: "customer_behavior_silver"
    fx_rates: "fx_rates_silver"
    order_events: "order_events_silver"
  
  gold:
    dim_customer: "dim_customer"
    dim_account: "dim_account"
    dim_contact: "dim_contact"
    dim_product: "dim_product"
    fact_orders: "fact_orders"
    fact_opportunity: "fact_opportunity"
    fact_order_events: "fact_order_events"
    customer_360: "customer_360"
    behavior_analytics: "behavior_analytics"

dq:
  mode: "strict"           # stop pipeline on critical failures
  fail_on_error: true
  alert_on_warning: true
  sampling:
    enabled: true
    fraction: 0.02
    max_rows: 200000
    seed: 42
  profiling:
    enabled: true
    output_path: "artifacts/dq/profiles"
    max_columns: 50
    top_values: 10
  drift:
    enabled: true
    baseline_path: "artifacts/dq/profile_baselines"
    null_pct_delta: 5.0
    distinct_pct_delta: 10.0
    avg_pct_delta: 20.0
    fail_on_drift: true
  reconciliation:
    enabled: true
    row_sample: 5000
    tolerance_pct: 2.5
  realism:
    enabled: true
    max_future_days: 3
    max_past_years: 5
    fail_on_violation: true

schema_evolution:
  enabled: true
  baseline_path: "artifacts/schema_baselines"
  update_baseline: false
  policies:
    bronze: "backward_compatible"
    silver: "backward_compatible"
    gold: "strict"

contracts:
  path: "config/contracts/silver_contracts.yaml"

incremental:
  orders_lookback_days: 3

monitoring:
  metrics_enabled: true
  alerts_enabled: true
  alerts_path: "artifacts/alerts/alerts.jsonl"
  audit_path: "artifacts/audit/pipeline_run_audit.jsonl"
  thresholds:
    bronze_to_silver_duration_seconds: 2700
    silver_to_gold_duration_seconds: 2700
  slo:
    pipeline_runtime_seconds: 7200
    freshness_hours: 36

sinks:
  redshift:
    jdbc_url: "jdbc:redshift://HOST:5439/DB"
    user: "redshift_user"
    password: "******"
  snowflake:
    url: "account.snowflakecomputing.com"
    user: "SF_USER"
    password: "******"
    database: "ANALYTICS"
    schema: "PUBLIC"
    warehouse: "COMPUTE_WH"
    role: "SYSADMIN"

lineage:
  enabled: true
  backend: "openlineage"
  endpoint: "http://marquez:5000"   # placeholder
  namespace: "project-a-dev"
  storage_path: "artifacts/lineage"

sla:
  bronze_ready_by: "02:30"
  silver_ready_by: "03:15"
  gold_ready_by: "04:00"

# Legacy source connection configs (for live connections)
source_connections:
  snowflake:
    secret_name: "project-a-dev/snowflake/conn"
    default_warehouse: "DEV_WH"
    default_database: "CUSTOMER_DB"
    default_schema: "PUBLIC"

  redshift:
    secret_name: "project-a-dev/redshift/conn"

  kafka:
    secret_name: "project-a-dev/kafka/conn"

  salesforce:
    secret_name: "project-a-dev/salesforce/conn"

  fx_api:
    secret_name: "project-a-dev/fx/conn"

# Sink configurations (dual sink: S3 + Snowflake)
sinks:
  snowflake:
    enabled: true
    account: "${SNOWFLAKE_ACCOUNT}"  # e.g., "xy12345.us-east-1"
    user: "PROJECT_A_INGEST"
    password_secret_name: "/project-a/dev/snowflake/password"  # AWS Secrets Manager
    role: "DATA_ENG_ROLE"
    warehouse: "WH_DATA_ENG"
    database: "PROJECT_A"
    schema: "ANALYTICS"
    tables:
      fact_orders: "FACT_ORDERS_DAILY"
      dim_customer: "DIM_CUSTOMER"
      dim_product: "DIM_PRODUCT"
      customer_360: "CUSTOMER_360"
    # Snowflake Spark connector options
    connector_jar: "net.snowflake:snowflake-jdbc:3.13.29,net.snowflake:spark-snowflake_2.12:2.12.0-spark_3.3"
