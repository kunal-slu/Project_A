app_name: pyspark_interview_project
cloud: local

io:
  format: csv
  compression: null

# Lakehouse configuration
lakehouse:
  base_path: "data/lakehouse_delta"
  bronze: "data/lakehouse_delta/bronze"
  silver: "data/lakehouse_delta/silver"
  gold: "data/lakehouse_delta/gold"

# Delta Lake path for CLI
delta_path: "data/lakehouse_delta_standard"

# Legacy paths (for compatibility)
paths:
  bronze:
    customers: data/input_data/customers.csv
    orders: data/input_data/orders.json
    products: data/input_data/products.csv
  silver:
    customers: data/lakehouse_delta/silver/customers
    orders: data/lakehouse_delta/silver/orders
    products: data/lakehouse_delta/silver/products
  gold:
    customers: data/lakehouse_delta/gold/customers
    orders: data/lakehouse_delta/gold/orders
    products: data/lakehouse_delta/gold/products

spark:
  master: "local[*]"
  shuffle_partitions: 400
  enable_aqe: true
  driver_memory: "2g"
  executor_memory: "4g"
  delta:
    enable_optimizations: true

dq:
  enabled: true
  null_threshold: 0.1
  duplicate_threshold: 0.05
