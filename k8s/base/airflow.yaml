apiVersion: v1
kind: Service
metadata:
  name: airflow-webserver
  namespace: pyspark-etl
  labels:
    app: airflow
    component: webserver
spec:
  type: LoadBalancer
  ports:
    - port: 8080
      targetPort: 8080
      protocol: TCP
      name: http
  selector:
    app: airflow
    component: webserver

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
  namespace: pyspark-etl
  labels:
    app: airflow
    component: webserver
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow
      component: webserver
  template:
    metadata:
      labels:
        app: airflow
        component: webserver
    spec:
      initContainers:
        - name: wait-for-postgres
          image: postgres:14-alpine
          command:
            - sh
            - -c
            - |
              until pg_isready -h postgres -U airflow; do
                echo "Waiting for postgres..."
                sleep 2
              done
        - name: init-airflow-db
          image: apache/airflow:2.9.3-python3.11
          command:
            - bash
            - -c
            - |
              airflow db migrate
          envFrom:
            - configMapRef:
                name: pyspark-etl-config
          env:
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: "postgresql+psycopg2://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)"
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: pyspark-etl-secrets
                  key: postgres-user
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: pyspark-etl-secrets
                  key: postgres-password
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: pyspark-etl-secrets
                  key: postgres-db
      containers:
        - name: webserver
          image: apache/airflow:2.9.3-python3.11
          ports:
            - containerPort: 8080
              name: http
          envFrom:
            - configMapRef:
                name: pyspark-etl-config
          env:
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: "postgresql+psycopg2://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)"
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: pyspark-etl-secrets
                  key: postgres-user
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: pyspark-etl-secrets
                  key: postgres-password
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: pyspark-etl-secrets
                  key: postgres-db
          command:
            - bash
            - -c
            - |
              airflow users create --username $(AIRFLOW_ADMIN_USER) --firstname Admin --lastname User --role Admin --email admin@example.com --password $(AIRFLOW_ADMIN_PASSWORD) || true
              airflow webserver
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
            - name: logs
              mountPath: /opt/airflow/logs
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "2Gi"
              cpu: "1000m"
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
      volumes:
        - name: dags
          emptyDir: {}
        - name: logs
          emptyDir: {}

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  namespace: pyspark-etl
  labels:
    app: airflow
    component: scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow
      component: scheduler
  template:
    metadata:
      labels:
        app: airflow
        component: scheduler
    spec:
      initContainers:
        - name: wait-for-postgres
          image: postgres:14-alpine
          command:
            - sh
            - -c
            - |
              until pg_isready -h postgres -U airflow; do
                echo "Waiting for postgres..."
                sleep 2
              done
      containers:
        - name: scheduler
          image: apache/airflow:2.9.3-python3.11
          envFrom:
            - configMapRef:
                name: pyspark-etl-config
          env:
            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
              value: "postgresql+psycopg2://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres:5432/$(POSTGRES_DB)"
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: pyspark-etl-secrets
                  key: postgres-user
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: pyspark-etl-secrets
                  key: postgres-password
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: pyspark-etl-secrets
                  key: postgres-db
          command:
            - bash
            - -c
            - |
              airflow scheduler
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
            - name: logs
              mountPath: /opt/airflow/logs
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "2Gi"
              cpu: "1000m"
          livenessProbe:
            exec:
              command:
                - bash
                - -c
                - |
                  airflow jobs check --job-type SchedulerJob --hostname $(hostname)
            initialDelaySeconds: 60
            periodSeconds: 30
      volumes:
        - name: dags
          emptyDir: {}
        - name: logs
          emptyDir: {}

