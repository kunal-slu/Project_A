# Enterprise AWS ETL Configuration
# This configuration uses REAL external data sources that enterprises actually use

# AWS-specific configuration
aws:
  region: "us-east-1"
  s3:
    # Separate storage buckets for different data sources
    ecommerce_data_bucket: "company-ecommerce-raw-data-ACCOUNT_ID"
    marketing_data_bucket: "company-marketing-data-ACCOUNT_ID"
    analytics_data_bucket: "company-analytics-data-ACCOUNT_ID"
    payment_data_bucket: "company-payment-data-ACCOUNT_ID"
    support_data_bucket: "company-support-data-ACCOUNT_ID"
    hr_data_bucket: "company-hr-data-ACCOUNT_ID"
    finance_data_bucket: "company-finance-data-ACCOUNT_ID"
    crm_data_bucket: "company-crm-data-ACCOUNT_ID"
    erp_data_bucket: "company-erp-data-ACCOUNT_ID"
    iot_data_bucket: "company-iot-data-ACCOUNT_ID"
    
    # Data lake storage
    data_lake_bucket: "company-data-lake-ACCOUNT_ID"
    backup_bucket: "company-backups-ACCOUNT_ID"
    logs_bucket: "company-logs-ACCOUNT_ID"
    artifacts_bucket: "company-artifacts-ACCOUNT_ID"
    
    # Cross-region backup
    backup_west_bucket: "company-backups-west-ACCOUNT_ID"
  
  emr:
    cluster_name: "enterprise-etl-cluster"
    release_label: "emr-6.15.0"
    instance_type: "m5.2xlarge"
    instance_count: 5
    applications: ["Spark", "Hive", "Hadoop", "Delta"]
  
  glue:
    database_name: "company_data_warehouse"
    crawler_name: "enterprise-data-crawler"
  
  step_functions:
    state_machine_name: "enterprise-etl-workflow"
  
  cloudwatch:
    namespace: "CompanyETL"
    log_group: "/aws/emr/company-etl"
  
  kinesis:
    stream_name: "company-real-time-data-stream"
    firehose_name: "company-data-firehose"
  
  msk:
    cluster_name: "company-kafka-cluster"
    topic_prefix: "company-data"

# Real external data sources that enterprises actually use
external_data_sources:
  # Cloud Data Warehouses
  snowflake:
    account: "company.snowflakecomputing.com"
    warehouse: "ETL_WH"
    database: "RAW_DATA"
    schema: "PUBLIC"
    username: "${SNOWFLAKE_USERNAME}"
    password: "${SNOWFLAKE_PASSWORD}"
    role: "ETL_ROLE"
    tables:
      - name: "customer_orders"
        source: "salesforce_orders"
        frequency: "hourly"
      - name: "product_catalog"
        source: "netsuite_products"
        frequency: "daily"
      - name: "financial_transactions"
        source: "quickbooks_transactions"
        frequency: "daily"
  
  redshift:
    cluster_identifier: "company-data-warehouse"
    database: "analytics"
    port: 5439
    username: "${REDSHIFT_USERNAME}"
    password: "${REDSHIFT_PASSWORD}"
    tables:
      - name: "marketing_campaigns"
        source: "google_ads_api"
        frequency: "hourly"
      - name: "customer_behavior"
        source: "amplitude_events"
        frequency: "real-time"
  
  bigquery:
    project_id: "company-analytics"
    dataset: "raw_data"
    location: "US"
    tables:
      - name: "web_analytics"
        source: "google_analytics_4"
        frequency: "daily"
      - name: "mobile_analytics"
        source: "firebase_analytics"
        frequency: "daily"
  
  # Relational Databases
  postgresql:
    host: "company-prod-db.company.com"
    port: 5432
    database: "company_production"
    username: "${POSTGRES_USERNAME}"
    password: "${POSTGRES_PASSWORD}"
    ssl_mode: "require"
    tables:
      - name: "users"
        schema: "public"
        frequency: "daily"
      - name: "subscriptions"
        schema: "billing"
        frequency: "hourly"
      - name: "product_inventory"
        schema: "inventory"
        frequency: "real-time"
  
  mysql:
    host: "company-legacy-db.company.com"
    port: 3306
    database: "legacy_systems"
    username: "${MYSQL_USERNAME}"
    password: "${MYSQL_PASSWORD}"
    ssl_mode: "required"
    tables:
      - name: "customer_data"
        frequency: "daily"
      - name: "order_history"
        frequency: "daily"
  
  sqlserver:
    host: "company-erp-db.company.com"
    port: 1433
    database: "erp_system"
    username: "${SQLSERVER_USERNAME}"
    password: "${SQLSERVER_PASSWORD}"
    tables:
      - name: "inventory_movements"
        frequency: "hourly"
      - name: "financial_reports"
        frequency: "daily"
  
  oracle:
    host: "company-hr-db.company.com"
    port: 1521
    service_name: "HRPROD"
    username: "${ORACLE_USERNAME}"
    password: "${ORACLE_PASSWORD}"
    tables:
      - name: "employee_data"
        frequency: "weekly"
      - name: "payroll_records"
        frequency: "monthly"
  
  # NoSQL Databases
  mongodb:
    connection_string: "mongodb://company-mongo.company.com:27017"
    database: "company_analytics"
    username: "${MONGODB_USERNAME}"
    password: "${MONGODB_PASSWORD}"
    collections:
      - name: "user_sessions"
        frequency: "real-time"
      - name: "product_reviews"
        frequency: "daily"
  
  dynamodb:
    region: "us-east-1"
    tables:
      - name: "user_preferences"
        frequency: "real-time"
      - name: "session_data"
        frequency: "real-time"
  
  # Streaming Platforms
  kafka:
    bootstrap_servers: "company-kafka.company.com:9092"
    security_protocol: "SASL_SSL"
    sasl_mechanism: "PLAIN"
    username: "${KAFKA_USERNAME}"
    password: "${KAFKA_PASSWORD}"
    topics:
      - name: "user_events"
        partitions: 12
        frequency: "real-time"
      - name: "order_events"
        partitions: 8
        frequency: "real-time"
      - name: "inventory_updates"
        partitions: 6
        frequency: "real-time"
  
  # API Sources
  apis:
    salesforce:
      base_url: "https://company.salesforce.com"
      api_version: "58.0"
      client_id: "${SALESFORCE_CLIENT_ID}"
      client_secret: "${SALESFORCE_CLIENT_SECRET}"
      refresh_token: "${SALESFORCE_REFRESH_TOKEN}"
      endpoints:
        - name: "leads"
          path: "/services/data/v58.0/sobjects/Lead"
          frequency: "hourly"
        - name: "opportunities"
          path: "/services/data/v58.0/sobjects/Opportunity"
          frequency: "hourly"
        - name: "accounts"
          path: "/services/data/v58.0/sobjects/Account"
          frequency: "daily"
    
    hubspot:
      base_url: "https://api.hubapi.com"
      api_key: "${HUBSPOT_API_KEY}"
      endpoints:
        - name: "contacts"
          path: "/crm/v3/objects/contacts"
          frequency: "hourly"
        - name: "deals"
          path: "/crm/v3/objects/deals"
          frequency: "hourly"
        - name: "companies"
          path: "/crm/v3/objects/companies"
          frequency: "daily"
    
    shopify:
      shop_url: "company.myshopify.com"
      access_token: "${SHOPIFY_ACCESS_TOKEN}"
      api_version: "2024-01"
      endpoints:
        - name: "orders"
          path: "/admin/api/2024-01/orders.json"
          frequency: "hourly"
        - name: "products"
          path: "/admin/api/2024-01/products.json"
          frequency: "daily"
        - name: "customers"
          path: "/admin/api/2024-01/customers.json"
          frequency: "daily"
    
    stripe:
      api_key: "${STRIPE_SECRET_KEY}"
      webhook_secret: "${STRIPE_WEBHOOK_SECRET}"
      endpoints:
        - name: "charges"
          path: "/v1/charges"
          frequency: "real-time"
        - name: "customers"
          path: "/v1/customers"
          frequency: "hourly"
        - name: "subscriptions"
          path: "/v1/subscriptions"
          frequency: "hourly"
    
    google_ads:
      client_id: "${GOOGLE_ADS_CLIENT_ID}"
      client_secret: "${GOOGLE_ADS_CLIENT_SECRET}"
      refresh_token: "${GOOGLE_ADS_REFRESH_TOKEN}"
      customer_id: "${GOOGLE_ADS_CUSTOMER_ID}"
      endpoints:
        - name: "campaigns"
          path: "/googleads/v14/customers/{customer_id}/googleAds:searchStream"
          frequency: "daily"
        - name: "ad_groups"
          path: "/googleads/v14/customers/{customer_id}/googleAds:searchStream"
          frequency: "daily"
    
    facebook_ads:
      access_token: "${FACEBOOK_ACCESS_TOKEN}"
      ad_account_id: "${FACEBOOK_AD_ACCOUNT_ID}"
      endpoints:
        - name: "campaigns"
          path: "/v18.0/act_{ad_account_id}/campaigns"
          frequency: "daily"
        - name: "ads"
          path: "/v18.0/act_{ad_account_id}/ads"
          frequency: "daily"
    
    linkedin_ads:
      client_id: "${LINKEDIN_CLIENT_ID}"
      client_secret: "${LINKEDIN_CLIENT_SECRET}"
      access_token: "${LINKEDIN_ACCESS_TOKEN}"
      endpoints:
        - name: "campaigns"
          path: "/v2/adCampaigns"
          frequency: "daily"
        - name: "ads"
          path: "/v2/ads"
          frequency: "daily"
  
  # File Storage Systems
  sftp:
    host: "company-sftp.company.com"
    port: 22
    username: "${SFTP_USERNAME}"
    password: "${SFTP_PASSWORD}"
    directories:
      - name: "vendor_data"
        path: "/incoming/vendor_data"
        frequency: "daily"
      - name: "partner_reports"
        path: "/incoming/partner_reports"
        frequency: "weekly"
  
  ftp:
    host: "company-legacy-ftp.company.com"
    port: 21
    username: "${FTP_USERNAME}"
    password: "${FTP_PASSWORD}"
    directories:
      - name: "legacy_reports"
        path: "/reports"
        frequency: "daily"
  
  # Cloud Storage
  google_cloud_storage:
    bucket: "company-gcs-data"
    project_id: "company-gcp-project"
    service_account_key: "${GCS_SERVICE_ACCOUNT_KEY}"
    objects:
      - name: "bigquery_exports"
        prefix: "exports/bigquery/"
        frequency: "daily"
      - name: "analytics_exports"
        prefix: "exports/analytics/"
        frequency: "daily"
  
  azure_blob_storage:
    account_name: "companyazurestorage"
    container: "company-data"
    connection_string: "${AZURE_CONNECTION_STRING}"
    blobs:
      - name: "powerbi_exports"
        prefix: "exports/powerbi/"
        frequency: "daily"
      - name: "dynamics_exports"
        prefix: "exports/dynamics/"
        frequency: "daily"
  
  # IoT and Real-time Data
  iot_core:
    endpoint: "company-iot.iot.us-east-1.amazonaws.com"
    thing_name: "company-sensors"
    certificates:
      - name: "sensor_cert"
        cert_id: "${IOT_CERT_ID}"
        cert_arn: "${IOT_CERT_ARN}"
    topics:
      - name: "sensor_data"
        topic: "company/sensors/+/data"
        frequency: "real-time"
      - name: "device_status"
        topic: "company/devices/+/status"
        frequency: "real-time"
  
  # Third-party SaaS Platforms
  mixpanel:
    project_id: "${MIXPANEL_PROJECT_ID}"
    api_secret: "${MIXPANEL_API_SECRET}"
    endpoints:
      - name: "events"
        path: "/api/2.0/export"
        frequency: "daily"
      - name: "funnels"
        path: "/api/2.0/funnels"
        frequency: "daily"
  
  amplitude:
    api_key: "${AMPLITUDE_API_KEY}"
    secret_key: "${AMPLITUDE_SECRET_KEY}"
    endpoints:
      - name: "events"
        path: "/2/events/segmentation"
        frequency: "daily"
      - name: "user_properties"
        path: "/2/user_properties"
        frequency: "daily"
  
  segment:
    write_key: "${SEGMENT_WRITE_KEY}"
    endpoints:
      - name: "events"
        path: "/v1/track"
        frequency: "real-time"
      - name: "identify"
        path: "/v1/identify"
        frequency: "real-time"
  
  # Enterprise Systems
  sap:
    host: "company-sap.company.com"
    client: "100"
    username: "${SAP_USERNAME}"
    password: "${SAP_PASSWORD}"
    language: "EN"
    tables:
      - name: "sales_orders"
        table: "VBAK"
        frequency: "hourly"
      - name: "material_master"
        table: "MAKT"
        frequency: "daily"
      - name: "financial_documents"
        table: "BKPF"
        frequency: "daily"
  
  workday:
    tenant: "company"
    username: "${WORKDAY_USERNAME}"
    password: "${WORKDAY_PASSWORD}"
    endpoints:
      - name: "employees"
        path: "/ccx/api/v1/workers"
        frequency: "weekly"
      - name: "positions"
        path: "/ccx/api/v1/positions"
        frequency: "weekly"
      - name: "organizations"
        path: "/ccx/api/v1/organizations"
        frequency: "weekly"
  
  netsuite:
    account_id: "${NETSUITE_ACCOUNT_ID}"
    consumer_key: "${NETSUITE_CONSUMER_KEY}"
    consumer_secret: "${NETSUITE_CONSUMER_SECRET}"
    token_id: "${NETSUITE_TOKEN_ID}"
    token_secret: "${NETSUITE_TOKEN_SECRET}"
    endpoints:
      - name: "customers"
        path: "/record/v1/customer"
        frequency: "daily"
      - name: "sales_orders"
        path: "/record/v1/salesorder"
        frequency: "hourly"
      - name: "inventory_items"
        path: "/record/v1/inventoryitem"
        frequency: "daily"

# Data lake paths with separate storage
data_lake:
  bronze_path: "s3://company-data-lake-ACCOUNT_ID/bronze"
  silver_path: "s3://company-data-lake-ACCOUNT_ID/silver"
  gold_path: "s3://company-data-lake-ACCOUNT_ID/gold"
  metrics_path: "s3://company-data-lake-ACCOUNT_ID/metrics"
  checkpoint_path: "s3://company-data-lake-ACCOUNT_ID/checkpoints"
  warehouse_path: "s3://company-data-lake-ACCOUNT_ID/warehouse"
  backup_path: "s3://company-backups-ACCOUNT_ID"

# Separate storage for different data types
storage_config:
  # E-commerce data storage
  ecommerce:
    raw_path: "s3://company-ecommerce-raw-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/ecommerce"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/ecommerce"
    backup_path: "s3://company-backups-ACCOUNT_ID/ecommerce"
  
  # Marketing data storage
  marketing:
    raw_path: "s3://company-marketing-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/marketing"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/marketing"
    backup_path: "s3://company-backups-ACCOUNT_ID/marketing"
  
  # Analytics data storage
  analytics:
    raw_path: "s3://company-analytics-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/analytics"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/analytics"
    backup_path: "s3://company-backups-ACCOUNT_ID/analytics"
  
  # Payment data storage (encrypted)
  payments:
    raw_path: "s3://company-payment-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/payments"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/payments"
    backup_path: "s3://company-backups-ACCOUNT_ID/payments"
  
  # Support data storage
  support:
    raw_path: "s3://company-support-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/support"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/support"
    backup_path: "s3://company-backups-ACCOUNT_ID/support"
  
  # HR data storage (restricted)
  hr:
    raw_path: "s3://company-hr-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/hr"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/hr"
    backup_path: "s3://company-backups-ACCOUNT_ID/hr"
  
  # Finance data storage (high security)
  finance:
    raw_path: "s3://company-finance-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/finance"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/finance"
    backup_path: "s3://company-backups-ACCOUNT_ID/finance"
  
  # CRM data storage
  crm:
    raw_path: "s3://company-crm-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/crm"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/crm"
    backup_path: "s3://company-backups-ACCOUNT_ID/crm"
  
  # ERP data storage
  erp:
    raw_path: "s3://company-erp-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/erp"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/erp"
    backup_path: "s3://company-backups-ACCOUNT_ID/erp"
  
  # IoT data storage
  iot:
    raw_path: "s3://company-iot-data-ACCOUNT_ID"
    processed_path: "s3://company-data-lake-ACCOUNT_ID/bronze/iot"
    analytics_path: "s3://company-data-lake-ACCOUNT_ID/gold/iot"
    backup_path: "s3://company-backups-ACCOUNT_ID/iot"

# Spark configuration for production
spark:
  app_name: "Company Enterprise ETL"
  config:
    # Delta Lake configuration
    spark.sql.extensions: "io.delta.sql.DeltaSparkSessionExtension"
    spark.sql.catalog.spark_catalog: "org.apache.spark.sql.delta.catalog.DeltaCatalog"
    spark.sql.catalog.spark_catalog.warehouse: "s3://company-data-lake-ACCOUNT_ID/warehouse"
    
    # S3 configuration for multiple buckets
    spark.hadoop.fs.s3a.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
    spark.hadoop.fs.s3a.aws.credentials.provider: "com.amazonaws.auth.DefaultAWSCredentialsProviderChain"
    spark.hadoop.fs.s3a.endpoint: "s3.amazonaws.com"
    spark.hadoop.fs.s3a.path.style.access: "false"
    
    # JDBC configurations for external databases
    spark.sql.adaptive.enabled: "true"
    spark.sql.adaptive.coalescePartitions.enabled: "true"
    spark.sql.adaptive.skewJoin.enabled: "true"
    spark.sql.adaptive.localShuffleReader.enabled: "true"
    spark.sql.adaptive.advisoryPartitionSizeInBytes: "128m"
    spark.sql.adaptive.maxShuffledHashJoinLocalMapThreshold: "0"
    spark.sql.adaptive.maxBroadcastHashJoinLocalMapThreshold: "0"
    spark.sql.adaptive.optimizeSkewedJoin.enabled: "true"
    spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes: "256m"
    spark.sql.adaptive.skewJoin.skewedPartitionFactor: "5"
    spark.sql.adaptive.coalescePartitions.minPartitionNum: "1"
    spark.sql.adaptive.coalescePartitions.initialPartitionNum: "200"
    spark.sql.adaptive.coalescePartitions.parallelismFirst: "false"
    spark.sql.adaptive.fetchShuffleBlocksInBatch.enabled: "true"
    spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin: "0.2"
    
    # Memory and execution
    spark.executor.memory: "8g"
    spark.executor.cores: "4"
    spark.driver.memory: "4g"
    spark.sql.shuffle.partitions: "200"
    spark.default.parallelism: "200"
    
    # Delta Lake optimization
    spark.databricks.delta.optimizeWrite.enabled: "true"
    spark.databricks.delta.autoCompact.enabled: "true"
    spark.databricks.delta.properties.defaults.enableChangeDataFeed: "true"
    
    # Streaming configurations
    spark.sql.streaming.checkpointLocation: "s3://company-data-lake-ACCOUNT_ID/checkpoints"
    spark.sql.streaming.schemaInference: "true"
    spark.sql.streaming.metricsEnabled: "true"

# Performance optimization settings
performance:
  cache_enabled: true
  partition_size_mb: 128
  max_partitions: 200
  broadcast_threshold_mb: 10
  shuffle_partitions: 200
  executor_instances: 5
  executor_memory: "8g"
  executor_cores: 4

# Monitoring configuration
monitoring:
  enabled: true
  metrics_export: "cloudwatch"
  log_level: "INFO"
  pipeline_metrics: true
  custom_metrics:
    - name: "RecordsProcessed"
      type: "counter"
    - name: "ProcessingTime"
      type: "gauge"
    - name: "DataQualityScore"
      type: "gauge"
    - name: "ErrorCount"
      type: "counter"
    - name: "StorageUsage"
      type: "gauge"
    - name: "SourceLatency"
      type: "gauge"
    - name: "APIResponseTime"
      type: "gauge"

# Data quality settings
data_quality:
  enabled: true
  validation_rules:
    # E-commerce data quality rules
    - name: "order_id_not_null"
      rule: "order_id IS NOT NULL"
      table: "orders"
    - name: "customer_id_not_null"
      rule: "customer_id IS NOT NULL"
      table: "customers"
    - name: "positive_amount"
      rule: "total_amount > 0"
      table: "orders"
    - name: "valid_email_format"
      rule: "email REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$'"
      table: "customers"
    - name: "valid_date_range"
      rule: "order_date BETWEEN '2020-01-01' AND CURRENT_DATE"
      table: "orders"
    
    # Payment data quality rules
    - name: "payment_status_valid"
      rule: "status IN ('succeeded', 'pending', 'failed', 'refunded')"
      table: "payments"
    - name: "positive_payment_amount"
      rule: "amount > 0"
      table: "payments"
    
    # Analytics data quality rules
    - name: "session_id_not_null"
      rule: "session_id IS NOT NULL"
      table: "analytics_sessions"
    - name: "valid_event_timestamp"
      rule: "event_timestamp <= CURRENT_TIMESTAMP"
      table: "analytics_events"
    
    # CRM data quality rules
    - name: "lead_source_valid"
      rule: "lead_source IN ('website', 'referral', 'social', 'email', 'phone')"
      table: "leads"
    - name: "opportunity_stage_valid"
      rule: "stage IN ('prospecting', 'qualification', 'proposal', 'negotiation', 'closed_won', 'closed_lost')"
      table: "opportunities"

# Streaming configuration
streaming:
  enable: true
  checkpoint_location: "s3://company-data-lake-ACCOUNT_ID/checkpoints"
  trigger_interval: "5 minutes"
  kinesis:
    stream_name: "company-real-time-data-stream"
    region: "us-east-1"
    batch_size: 1000
    max_records_per_batch: 10000
  kafka:
    bootstrap_servers: "company-kafka.company.com:9092"
    topics:
      - "user_events"
      - "order_events"
      - "inventory_updates"
  msk:
    cluster_name: "company-kafka-cluster"
    topics:
      - "customer_behavior"
      - "product_interactions"
      - "system_metrics"

# Disaster recovery settings
disaster_recovery:
  enabled: true
  backup_frequency: "hourly"
  retention_days: 90
  replication_enabled: true
  backup_location: "s3://company-backups-ACCOUNT_ID"
  cross_region_backup:
    enabled: true
    destination_region: "us-west-2"
    destination_bucket: "s3://company-backups-west-ACCOUNT_ID"
  rto_hours: 4  # Recovery Time Objective
  rpo_hours: 1  # Recovery Point Objective

# Maintenance settings
maintenance:
  enable: true
  delta_vacuum_retention_hours: 168  # 7 days
  delta_optimize_frequency: "daily"
  z_order_columns:
    - "customer_id"
    - "order_date"
    - "product_id"
    - "country"
    - "category"
  cleanup_old_data:
    enabled: true
    retention_days: 1095  # 3 years
    tables:
      - "bronze_orders"
      - "bronze_analytics_events"
      - "bronze_support_tickets"
  data_archival:
    enabled: true
    archival_threshold_days: 365
    archival_storage_class: "GLACIER"
    archival_bucket: "s3://company-archives-ACCOUNT_ID"

# Security settings
security:
  encryption_enabled: true
  audit_logging: true
  data_masking: true
  access_control:
    - role: "data_engineer"
      permissions: ["read", "write", "delete"]
      tables: ["*"]
    - role: "data_analyst"
      permissions: ["read"]
      tables: ["gold_*", "silver_*"]
    - role: "business_user"
      permissions: ["read"]
      tables: ["gold_fact_sales", "gold_dim_customers"]
    - role: "hr_analyst"
      permissions: ["read"]
      tables: ["gold_hr_*"]
      restricted_access: true
    - role: "finance_analyst"
      permissions: ["read"]
      tables: ["gold_finance_*"]
      high_security_access: true
    - role: "crm_analyst"
      permissions: ["read"]
      tables: ["gold_crm_*"]
    - role: "erp_analyst"
      permissions: ["read"]
      tables: ["gold_erp_*"]
  data_classification:
    pii_columns:
      - "email"
      - "phone"
      - "address"
      - "credit_card_number"
      - "ssn"
      - "salary"
      - "employee_id"
      - "customer_id"
    sensitive_columns:
      - "salary"
      - "revenue"
      - "profit_margin"
      - "customer_credit_limit"
      - "pricing"
      - "contract_terms"
    restricted_data:
      - "hr_employee_data"
      - "finance_transactions"
      - "payment_card_data"
      - "crm_customer_data"
      - "erp_inventory_data"
  compliance:
    gdpr_enabled: true
    ccpa_enabled: true
    sox_compliance: true
    hipaa_compliance: false
    data_retention_policies:
      - data_type: "pii"
        retention_days: 2555  # 7 years
      - data_type: "financial"
        retention_days: 3650  # 10 years
      - data_type: "operational"
        retention_days: 1095  # 3 years

# ETL pipeline configuration
etl_pipeline:
  # Ingestion jobs for different data sources
  ingestion:
    # External database ingestion
    snowflake_ingestion:
      enabled: true
      frequency: "hourly"
      batch_size: 10000
      timeout_minutes: 30
      source_type: "snowflake"
    redshift_ingestion:
      enabled: true
      frequency: "hourly"
      batch_size: 15000
      timeout_minutes: 45
      source_type: "redshift"
    postgresql_ingestion:
      enabled: true
      frequency: "hourly"
      batch_size: 5000
      timeout_minutes: 20
      source_type: "postgresql"
    mysql_ingestion:
      enabled: true
      frequency: "daily"
      batch_size: 10000
      timeout_minutes: 60
      source_type: "mysql"
    
    # API ingestion
    salesforce_ingestion:
      enabled: true
      frequency: "hourly"
      batch_size: 2000
      timeout_minutes: 30
      source_type: "api"
    hubspot_ingestion:
      enabled: true
      frequency: "hourly"
      batch_size: 2000
      timeout_minutes: 30
      source_type: "api"
    shopify_ingestion:
      enabled: true
      frequency: "hourly"
      batch_size: 5000
      timeout_minutes: 45
      source_type: "api"
    stripe_ingestion:
      enabled: true
      frequency: "real-time"
      batch_size: 1000
      timeout_minutes: 15
      source_type: "api"
    
    # Streaming ingestion
    kafka_ingestion:
      enabled: true
      frequency: "real-time"
      batch_size: 1000
      timeout_minutes: 10
      source_type: "streaming"
    kinesis_ingestion:
      enabled: true
      frequency: "real-time"
      batch_size: 1000
      timeout_minutes: 10
      source_type: "streaming"
    
    # File ingestion
    sftp_ingestion:
      enabled: true
      frequency: "daily"
      batch_size: 1000
      timeout_minutes: 60
      source_type: "file"
    gcs_ingestion:
      enabled: true
      frequency: "daily"
      batch_size: 5000
      timeout_minutes: 45
      source_type: "file"
  
  # Processing jobs
  processing:
    data_cleaning:
      enabled: true
      frequency: "hourly"
      dependencies: ["ingestion.*"]
    data_enrichment:
      enabled: true
      frequency: "hourly"
      dependencies: ["processing.data_cleaning"]
    data_validation:
      enabled: true
      frequency: "hourly"
      dependencies: ["processing.data_enrichment"]
    data_deduplication:
      enabled: true
      frequency: "hourly"
      dependencies: ["processing.data_validation"]
  
  # Data warehouse jobs
  data_warehouse:
    dimension_tables:
      enabled: true
      frequency: "daily"
      dependencies: ["processing.data_deduplication"]
    fact_tables:
      enabled: true
      frequency: "hourly"
      dependencies: ["data_warehouse.dimension_tables"]
    aggregate_tables:
      enabled: true
      frequency: "daily"
      dependencies: ["data_warehouse.fact_tables"]
    marts:
      enabled: true
      frequency: "daily"
      dependencies: ["data_warehouse.aggregate_tables"]

# Environment-specific settings
environment: "aws-enterprise-production"
region: "us-east-1"
timezone: "UTC"
data_retention_days: 1095  # 3 years
max_concurrent_jobs: 20
alert_email: "data-team@company.com"
sla_hours: 2  # Service Level Agreement in hours
rto_hours: 4  # Recovery Time Objective
rpo_hours: 1  # Recovery Point Objective
