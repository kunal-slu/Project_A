# PySpark Data Engineering Project

Comprehensive AWS Production ETL Pipeline with Delta Lake

## ğŸ¯ Project Overview

This is a production-ready data engineering project that demonstrates best practices for:
- Multi-source data ingestion (HubSpot, Snowflake, Redshift, Kafka, FX Rates)
- Bronze â†’ Silver â†’ Gold data lakehouse architecture
- Incremental loading with SCD2 support
- Data quality validation
- AWS EMR Serverless deployment
- Delta Lake for ACID transactions

## ğŸ“ Project Structure

```
pyspark_data_engineer_project/
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ local.yaml              # Local development
â”‚   â”œâ”€â”€ config-dev.yaml         # Dev environment
â”‚   â”œâ”€â”€ aws.yaml                # AWS production
â”‚   â””â”€â”€ dq.yaml                 # Data quality config
â”‚
â”œâ”€â”€ src/pyspark_interview_project/
â”‚   â”œâ”€â”€ utils/                   # Core utilities
â”‚   â”œâ”€â”€ extract.py               # Data extraction
â”‚   â”œâ”€â”€ transform.py             # Data transformation
â”‚   â”œâ”€â”€ load.py                  # Data loading
â”‚   â”œâ”€â”€ incremental_loading.py   # SCD2 & CDC
â”‚   â”œâ”€â”€ jobs/                    # EMR job implementations
â”‚   â”œâ”€â”€ dq/                      # Data quality
â”‚   â””â”€â”€ monitoring/              # Monitoring
â”‚
â”œâ”€â”€ jobs/                        # EMR job wrappers
â”œâ”€â”€ aws/
â”‚   â”œâ”€â”€ infra/terraform/        # Infrastructure as code
â”‚   â”œâ”€â”€ scripts/                 # Deployment scripts
â”‚   â””â”€â”€ emr_configs/            # EMR configuration
â”‚
â”œâ”€â”€ tests/                       # Test suite
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â””â”€â”€ docs/                        # Documentation
```

## ğŸš€ Quick Start

### Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Run tests
pytest tests/

# Run pipeline locally
python src/pyspark_interview_project/pipeline_core.py config/config-dev.yaml
```

### AWS Deployment

See [AWS_DEPLOYMENT_GUIDE.md](AWS_DEPLOYMENT_GUIDE.md) for complete deployment instructions.

## ğŸ“Š Data Sources

1. **HubSpot CRM** - Contacts and deals
2. **Snowflake** - Orders and customers
3. **Redshift** - Customer behavior analytics
4. **Kafka** - Real-time event streaming
5. **FX Rates** - Exchange rates from vendors

## ğŸ—ï¸ Architecture

- **Bronze Layer**: Raw data ingestion with schema validation
- **Silver Layer**: Cleaned, conformed data with SCD2 support
- **Gold Layer**: Business-ready dimensional models

## ğŸ”§ Key Features

- âœ… Incremental loading strategies
- âœ… SCD2 support for slowly changing dimensions
- âœ… Data quality checks with Great Expectations
- âœ… Delta Lake for ACID transactions
- âœ… AWS EMR Serverless deployment
- âœ… Monitoring and alerting

## ğŸ“– Documentation

- [AWS Deployment Guide](AWS_DEPLOYMENT_GUIDE.md)
- [Project Structure](PROJECT_FINAL_STRUCTURE.md)
- [AWS Runbook](RUNBOOK_AWS_2025.md)

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run specific test suite
pytest tests/test_contracts.py
```

## ğŸ“ Requirements

- Python 3.10+
- PySpark 3.5+
- Delta Lake
- AWS CLI configured
- Terraform 1.0+

## ğŸ“„ License

MIT License
